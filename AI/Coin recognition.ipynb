{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "datadir_train = \"classified/train\"\n",
    "datadir_test = \"classified/test\"\n",
    "categories = ['1c','2c', '5c', '10c', '20c', '50c', '1e', '2e']\n",
    "\n",
    "training_data = []\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir_train, category)\n",
    "    label = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))\n",
    "        img_array = cv2.resize(img_array, (500, 500))\n",
    "        mask = np.zeros(img_array.shape[:2],np.uint8)\n",
    "        bgdModel = np.zeros((1,65),np.float64)\n",
    "        fgdModel = np.zeros((1,65),np.float64)\n",
    "        rect = (50,50,450,290)\n",
    "        cv2.grabCut(img_array,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "        mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "        img_array = img_array*mask2[:,:,np.newaxis]\n",
    "        img_array = cv2.resize(img_array, (150,150))\n",
    "        training_data.append([img_array, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "    \n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir_test, category)\n",
    "    class_num = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))\n",
    "        img_array = cv2.resize(img_array, (500, 500))\n",
    "        mask = np.zeros(img_array.shape[:2],np.uint8)\n",
    "        bgdModel = np.zeros((1,65),np.float64)\n",
    "        fgdModel = np.zeros((1,65),np.float64)\n",
    "        rect = (50,50,450,290)\n",
    "        cv2.grabCut(img_array,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "        mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "        img_array = img_array*mask2[:,:,np.newaxis]\n",
    "        img_array = cv2.resize(img_array, (150,150))\n",
    "        testing_data.append([img_array, class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for features, label in testing_data:\n",
    "    x_test.append(features)\n",
    "    y_test.append(label)\n",
    "    \n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def k_nearest_neighbors(predict, k):\n",
    "    distences = []\n",
    "    for image in training_data:\n",
    "        distences.append([np.linalg.norm(image[0] - predict), image[1]])\n",
    "    distences.sort()\n",
    "    votes = [i[1] for i in distences[:k]]\n",
    "    votes = ''.join(str(e) for e in votes)\n",
    "    votes = votes.replace(',', '')\n",
    "    votes = votes.replace(' ', '')\n",
    "    result = Counter(votes).most_common(1)[0][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = ''.join(str(e) for e in y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.849449634552002\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "correct = 0\n",
    "total = 0\n",
    "for image in testing_data:\n",
    "    prediction = k_nearest_neighbors(image[0], 30)\n",
    "    if int(prediction) == image[1]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "accuracy = correct/total\n",
    "end = time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2625\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "filename = 'src/1e/IMG_4197.JPG'\n",
    "# Loads an image\n",
    "src = cv.imread(cv.samples.findFile(filename), cv.IMREAD_COLOR)\n",
    "# Check if image is loaded fine\n",
    "if src is None:\n",
    "    print('Error opening image!')\n",
    "    print('Usage: hough_circle.py [image_name -- default ' + default_file + '] \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img):\n",
    "    scale_percent = 500 / img.shape[1]\n",
    "    w = int(img.shape[1] * scale_percent)\n",
    "    h = int(img.shape[0] * scale_percent)\n",
    "    dim = (w, h)\n",
    "    new_img = cv.resize(img, dim)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = resize_img(src)\n",
    "\n",
    "gray = cv.cvtColor(new_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = cv.medianBlur(gray, 5)\n",
    "\n",
    "rows = gray.shape[0]\n",
    "circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, rows / 8, param1=100, param2=30, minRadius=1, maxRadius=70)\n",
    "\n",
    "circle_img = new_img\n",
    "numero_piece = 0\n",
    "Images = []\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "\n",
    "        radius = i[2]\n",
    "\n",
    "        img_name = str('piece' + str(numero_piece))\n",
    "        img_cropped = new_img[i[1] - (radius + 5):i[1] + (radius + 5), i[0] - (radius + 5):i[0] + (radius + 5), ]\n",
    "        numero_piece += 1\n",
    "        Images.append(img_cropped)\n",
    "        #cv.imshow(img_name, img_cropped)\n",
    "        #cv.imwrite(img_name + '.jpg', img_cropped)\n",
    "\n",
    "cv.imshow(\"detected circles\", circle_img)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-268-2c607de7a7be>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-268-2c607de7a7be>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    if prediction == 0:\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "somme_de_pieces = 0\n",
    "for image in Images:\n",
    "    prediction = k_nearest_neighbors(image[0], 30)\n",
    "    if prediction == 0:\n",
    "        somme_de_pieces += 0.01\n",
    "    if prediction == 1:\n",
    "        somme_de_pieces += 0.02\n",
    "    if prediction == 2:\n",
    "        somme_de_pieces += 0.05\n",
    "    if prediction == 3:\n",
    "        somme_de_pieces += 0.10\n",
    "    if prediction == 4:\n",
    "        somme_de_pieces += 0.20\n",
    "    if prediction == 5:\n",
    "        somme_de_pieces += 0.50\n",
    "    if prediction == 6:\n",
    "        somme_de_pieces += 1.00\n",
    "    if prediction == 7:\n",
    "        somme_de_pieces += 2.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction == 0:\n",
    "    print(\"la valeur de la pièce est de 1 centime\")\n",
    "elif prediction == 1:\n",
    "    print(\"la valeur de la pièce est de 2 centimes\")\n",
    "elif prediction == 2:\n",
    "    print(\"la valeur de la pièce est de 5 centimes\")\n",
    "elif prediction == 3:\n",
    "    print(\"la valeur de la pièce est de 10 centimes\")\n",
    "elif prediction == 4:\n",
    "    print(\"la valeur de la pièce est de 20 centimes\")\n",
    "elif prediction == 5:\n",
    "    print(\"la valeur de la pièce est de 50 centimes\")\n",
    "elif prediction == 6:\n",
    "    print(\"la valeur de la pièce est de 1 euro\")\n",
    "elif prediction == 7:\n",
    "    print(\"la valeur de la pièce est de 2 euros\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
